# ============================================
# OpenAI API Configuration
# ============================================

# Required: Your OpenAI API key
# Get it from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-proj-...

# Optional: Custom base URL for OpenAI-compatible APIs
# Default: https://api.openai.com/v1
# Use this for Azure OpenAI, LiteLLM, or other compatible endpoints
# OPENAI_BASE_URL=https://api.openai.com/v1

# Optional: Model to use for prompt enhancement
# Default: gpt-4o-mini
# Other options: gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# OPENAI_MODEL=gpt-4o-mini

# Optional: Number of images to generate per request
# Default: 2
# Range: 1-3 (DALL-E 3 generates sequentially)
# IMAGE_COUNT=2

# ============================================
# Development Notes
# ============================================

# 1. Copy this file to .env.local for local development:
#    cp .env.example .env.local
#
# 2. Never commit .env.local to version control (.gitignore blocks it)
#
# 3. For Vercel deployment, set these in the Vercel Dashboard:
#    Project Settings â†’ Environment Variables
#
# 4. Cost estimates (as of 2024):
#    - GPT-4o-mini: ~$0.15/1M input tokens, ~$0.60/1M output tokens
#    - DALL-E 3 (standard, 1024x1024): $0.040 per image
#    - DALL-E 3 (hd, 1024x1024): $0.080 per image
#
# 5. Rate limits (OpenAI default tier):
#    - GPT-4o-mini: 30,000 TPM (tokens per minute)
#    - DALL-E 3: 5 images/minute, 100 images/day
